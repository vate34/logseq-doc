- ZooKeeper的Leader选举存在两种场景。一个是服务器初次启动时，另一个是运行过程中Leader服务器宕机时。
- 重要参数：
	- myId，服务器ID，即SID，编号越大在选举算法中权重越大。
		- ((64b7e52b-f1ac-4e19-8327-271c3b9f9885))
	- ZXID，事务ID，值越大说明数据越新，权重越大。
	- epoch，逻辑时钟，logicalclock。同一轮投票过程中的逻辑时钟值是相同的，每投完一次值会增加
- 选举状态：
	- LOOKING，竞选状态
	- FOLLOWING，随从状态，同步Leader状态，参与投票
	- OBSERVING，观察状态，同步Leader状态，不参与投票
	- LEADING，领导者状态
- # 1.服务器启动时的Leader选举
	- 以五个服务节点集群的初次启动为例。第一次启动，都处于初始状态，`ZXID`都是0，`myid`分别为1、2、3、4、5。票据`（ZXID，myid）`分别为`（0,1）`、`（0,2）`、`（0,3）`、`（0,4）`、`（0,5）`。具体投票过程如下：
		- `myid=1` 的服务器启动，发起一次投票，服务器1给自己投1票，票数不过半，选举无法完成。
		- `myid=2` 的服务器启动，再发起一次投票，服务器1和服务器2分别给自己投一票。
		- 服务器1和服务器2交换选票信息，先比较`ZXID`，都是0，再 比较`myid`，服务器2的 `myid` 比服务器1大，所以服务器1的票据更改为`（0,2）`，服务器2不需要更改。
		- 统计选票，服务器1和服务器2变更选票信息后再次交换选票，服务器1和服务器2都有两张一样的票`（0,2）`,意为服务器2有两票，但是票数不过半，无法完成投票。
		- `myid=3` 的服务器启动，发起投票，此时服务器1和2持有的票据都是`（0,2）`，服务器3的票据为`（0,3）`，互相交换选票（每个服务器的票据都要广播给其他具有投票权的服务器），服务器3的 `myid` 比服务器2的 大，服务器1和2变更票据为`（0,3）`，服务器3保持不变。
		- 再次统计选票，服务器3有三张票，服务器1和2都是零票。服务器3持有的票数过半，`Leader`选举完成，服务器3成为 `Leader`，服务器1和2成为`Follower`。
		- `myid=4`的服务器启动，发现集群中已经有`Leader`了，就变更自己的角色状态为`Follower`。
		- `myid=5` 的服务器启动，同理也变更自己的角色状态为 `Follower`。
- 总结：
	- 交换选票。每个服务器将自己持有的票据广播给其他具有投票权的服务器。
	- 变更选票。每个服务器将自己的选票信息更新为，`ZXID`最大或者`myid`最大的服务器。
	- 统计选票。每个服务器广播一次自己持有的票据，每个服务器判断自己接收到的相同票据数量是否过半，是就推选该票据的`myid`对应的服务器成为`Leader`，其他成为`Follower`。
- # 2. 集群运行期间Leader选举
- 当一个节点无法与Leader保持通讯时，会与其他节点同步信息，当前集群可能处于两种状态：
	- 集群中已经存在Leader，且其他节点能够通讯，则不需要重新选举，当前节点尝试重新连接并进行状态同步即可。
	- 集群中确实不存在Leader，Leader故障挂掉，需要重新选举。
- Leader故障挂掉时，进行重新`Leader`选举，其过程与初次启动选举一样。成为新`Leader`必须满足两个条件：
	- 新`Leader`的`ZXID`是所有服务器中最大的，这就可以最大限度的恢复数据。
	- 新`Leader`不能包含未`COMMIT`的事务提议，如果事务日志文件中有未同步到内存数据库的事务将会回滚丢弃。
- # 3. 选举规则
- 简单梳理一下，无论是哪种场景，其规则都如下：
	- epoch大的胜出
	- epoch相同，ZXID大的胜出
	- ZXID相同，SID大的胜出